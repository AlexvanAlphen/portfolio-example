{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises \n",
    "# 1. Tune the network\n",
    "Run the experiment below, explore the different parameters (see suggestions below) and study the result with tensorboard. \n",
    "Make a single page (1 a4) report of your findings. Use your visualisation skills to communicate your most important findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from tomlserializer import TOMLSerializer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `tomlserializer` to easily keep track of our experiments, and to easily save the different things we did during our experiments.\n",
    "It can export things like settings and models to a simple `toml` file, which can be easily shared, checked and modified.\n",
    "\n",
    "First, we need the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-22 13:10:23.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mStart download...\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0.00/55.4M [00:00<?, ?iB/s]\u001b[32m2026-02-22 13:10:26.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.datatools\u001b[0m:\u001b[36mget_file\u001b[0m:\u001b[36m105\u001b[0m - \u001b[1mDownloading C:\\Users\\Alex\\.cache\\mads_datasets\\fashionmnist\\fashionmnist.pt\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 55.4M/55.4M [00:02<00:00, 23.9MiB/s]\n",
      "\u001b[32m2026-02-22 13:10:28.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m112\u001b[0m - \u001b[1mDigest of C:\\Users\\Alex\\.cache\\mads_datasets\\fashionmnist\\fashionmnist.pt matches expected digest\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "preprocessor = BasePreprocessor()\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=64, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to determine how well our model is performing. We will use accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set up a single experiment.\n",
    "\n",
    "- We will show the model batches of 64 images, \n",
    "- and for every epoch we will show the model 100 batches (trainsteps=100).\n",
    "- then, we will test how well the model is doing on unseen data (teststeps=100).\n",
    "- we will report our results during training to tensorboard, and report all configuration to a toml file.\n",
    "- we will log the results into a directory called \"modellogs\", but you could change this to whatever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-22 13:10:56.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m60\u001b[0m - \u001b[1mCreated logdir c:\\Users\\Alex\\Documents\\GitHub\\portfolio-example\\1-hypertuning-gridsearch\\modellogs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=3,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a very basic model: a model with three linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    num_classes=10, units1=256, units2=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developped the `tomlserializer` package, it is a useful tool to save configs, models and settings as a tomlfile; that way it is easy to track what you changed during your experiments.\n",
    "\n",
    "This package will 1. check if there is a `__dict__` attribute available, and if so, it will use that to extract the parameters that do not start with an underscore, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True, 'num_classes': 10, 'units1': 256, 'units2': 256}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in model.__dict__.items() if not k.startswith(\"_\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that if you want to add more parameters to the `.toml` file, eg `units3`, you can add them to the class like this:\n",
    "\n",
    "```python\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int, units3: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.units3 = units3  # <-- add this line\n",
    "```\n",
    "\n",
    "And then it will be added to the `.toml` file. Check the result for yourself by using the `.save()` method of the `TomlSerializer` class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomlserializer = TOMLSerializer()\n",
    "tomlserializer.save(settings, \"settings.toml\")\n",
    "tomlserializer.save(model, \"model.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `settings.toml` and `model.toml` files to see what is in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `Trainer` class from my `mltrainer` module to train your model. It has the TOMLserializer integrated, so it will automatically save the settings and model to a toml file if you have added `TOML` as a reporttype in the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-22 13:12:06.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20260222-131206\u001b[0m\n",
      "\u001b[32m2026-02-22 13:12:07.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 236.10it/s]\n",
      "\u001b[32m2026-02-22 13:12:08.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 0 train 0.9283 test 0.6315 metric ['0.7725']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 234.71it/s]\n",
      "\u001b[32m2026-02-22 13:12:09.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 1 train 0.5804 test 0.5416 metric ['0.8045']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 217.59it/s]\n",
      "\u001b[32m2026-02-22 13:12:10.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 2 train 0.5294 test 0.5683 metric ['0.7719']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:12:10.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.5416, current loss 0.5683.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check in the modellogs directory the results of your experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now loop this with a naive approach, called a grid-search (why do you think i call it naive?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units: 256, 256\n",
      "Units: 256, 128\n",
      "Units: 256, 64\n",
      "Units: 128, 256\n",
      "Units: 128, 128\n",
      "Units: 128, 64\n",
      "Units: 64, 256\n",
      "Units: 64, 128\n",
      "Units: 64, 64\n"
     ]
    }
   ],
   "source": [
    "units = [256, 128, 64]\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        print(f\"Units: {unit1}, {unit2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this might not be the best way to search for a model; some configurations will be better than others (can you predict up front what will be the best configuration?).\n",
    "\n",
    "So, feel free to improve upon the gridsearch by adding your own logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-02-22 13:21:31.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20260222-132131\u001b[0m\n",
      "\u001b[32m2026-02-22 13:21:31.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 237.01it/s]\n",
      "\u001b[32m2026-02-22 13:21:35.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 0 train 0.5134 test 0.4428 metric ['0.8322']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 236.02it/s]\n",
      "\u001b[32m2026-02-22 13:21:40.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 1 train 0.3640 test 0.3864 metric ['0.8597']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 233.57it/s]\n",
      "\u001b[32m2026-02-22 13:21:44.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 2 train 0.3290 test 0.3791 metric ['0.8617']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 211.29it/s]\n",
      "\u001b[32m2026-02-22 13:21:49.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 3 train 0.3048 test 0.3588 metric ['0.8726']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 205.38it/s]\n",
      "\u001b[32m2026-02-22 13:21:54.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 4 train 0.2869 test 0.3470 metric ['0.8752']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 193.65it/s]\n",
      "\u001b[32m2026-02-22 13:21:59.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 5 train 0.2733 test 0.3751 metric ['0.8675']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:21:59.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3470, current loss 0.3751.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 200.94it/s]\n",
      "\u001b[32m2026-02-22 13:22:04.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 6 train 0.2582 test 0.3426 metric ['0.8802']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 192.45it/s]\n",
      "\u001b[32m2026-02-22 13:22:10.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 7 train 0.2449 test 0.3721 metric ['0.8719']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:22:10.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3426, current loss 0.3721.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 188.70it/s]\n",
      "\u001b[32m2026-02-22 13:22:15.824\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 8 train 0.2417 test 0.3298 metric ['0.8836']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:05<00:00, 181.80it/s]\n",
      "\u001b[32m2026-02-22 13:22:21.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 9 train 0.2259 test 0.3382 metric ['0.8841']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:22:21.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3298, current loss 0.3382.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:49<00:00,  5.00s/it]\n",
      "\u001b[32m2026-02-22 13:22:21.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20260222-132221\u001b[0m\n",
      "\u001b[32m2026-02-22 13:22:21.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 250.37it/s]\n",
      "\u001b[32m2026-02-22 13:22:25.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 0 train 0.5199 test 0.4146 metric ['0.8508']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 239.28it/s]\n",
      "\u001b[32m2026-02-22 13:22:29.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 1 train 0.3692 test 0.3696 metric ['0.8661']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 240.62it/s]\n",
      "\u001b[32m2026-02-22 13:22:34.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 2 train 0.3301 test 0.3628 metric ['0.8703']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 223.19it/s]\n",
      "\u001b[32m2026-02-22 13:22:38.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 3 train 0.3063 test 0.3476 metric ['0.8743']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 202.29it/s]\n",
      "\u001b[32m2026-02-22 13:22:43.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 4 train 0.2862 test 0.3356 metric ['0.8783']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 197.02it/s]\n",
      "\u001b[32m2026-02-22 13:22:49.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 5 train 0.2753 test 0.3377 metric ['0.8817']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:22:49.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3356, current loss 0.3377.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 210.66it/s]\n",
      "\u001b[32m2026-02-22 13:22:54.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 6 train 0.2603 test 0.3168 metric ['0.8863']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 213.96it/s]\n",
      "\u001b[32m2026-02-22 13:22:58.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 7 train 0.2488 test 0.3410 metric ['0.8846']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:22:58.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3168, current loss 0.3410.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 190.43it/s]\n",
      "\u001b[32m2026-02-22 13:23:04.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 8 train 0.2342 test 0.3340 metric ['0.8826']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:23:04.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3168, current loss 0.3340.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 203.95it/s]\n",
      "\u001b[32m2026-02-22 13:23:09.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 9 train 0.2303 test 0.3185 metric ['0.8878']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:23:09.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3168, current loss 0.3185.Counter 3/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:47<00:00,  4.78s/it]\n",
      "\u001b[32m2026-02-22 13:23:09.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20260222-132309\u001b[0m\n",
      "\u001b[32m2026-02-22 13:23:09.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 220.89it/s]\n",
      "\u001b[32m2026-02-22 13:23:13.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 0 train 0.5364 test 0.4524 metric ['0.8370']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 194.93it/s]\n",
      "\u001b[32m2026-02-22 13:23:19.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 1 train 0.3777 test 0.3928 metric ['0.8589']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 199.94it/s]\n",
      "\u001b[32m2026-02-22 13:23:24.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 2 train 0.3429 test 0.3867 metric ['0.8622']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 219.95it/s]\n",
      "\u001b[32m2026-02-22 13:23:29.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 3 train 0.3120 test 0.3587 metric ['0.8691']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 216.96it/s]\n",
      "\u001b[32m2026-02-22 13:23:33.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 4 train 0.2959 test 0.3349 metric ['0.8776']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 228.75it/s]\n",
      "\u001b[32m2026-02-22 13:23:38.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 5 train 0.2822 test 0.3528 metric ['0.8761']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:23:38.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3349, current loss 0.3528.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 242.25it/s]\n",
      "\u001b[32m2026-02-22 13:23:42.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 6 train 0.2691 test 0.3260 metric ['0.8824']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 232.76it/s]\n",
      "\u001b[32m2026-02-22 13:23:46.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 7 train 0.2566 test 0.3499 metric ['0.8711']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:23:46.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3260, current loss 0.3499.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 235.24it/s]\n",
      "\u001b[32m2026-02-22 13:23:51.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 8 train 0.2507 test 0.3767 metric ['0.8687']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:23:51.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3260, current loss 0.3767.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 222.34it/s]\n",
      "\u001b[32m2026-02-22 13:23:56.095\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 9 train 0.2376 test 0.3248 metric ['0.8843']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:46<00:00,  4.68s/it]\n",
      "\u001b[32m2026-02-22 13:23:56.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20260222-132356\u001b[0m\n",
      "\u001b[32m2026-02-22 13:23:56.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 276.99it/s]\n",
      "\u001b[32m2026-02-22 13:23:59.867\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 0 train 0.5324 test 0.5163 metric ['0.8161']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 251.42it/s]\n",
      "\u001b[32m2026-02-22 13:24:03.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 1 train 0.3735 test 0.3930 metric ['0.8596']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 258.51it/s]\n",
      "\u001b[32m2026-02-22 13:24:08.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 2 train 0.3415 test 0.3784 metric ['0.8657']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 253.99it/s]\n",
      "\u001b[32m2026-02-22 13:24:12.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 3 train 0.3120 test 0.3732 metric ['0.8648']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 234.54it/s]\n",
      "\u001b[32m2026-02-22 13:24:16.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 4 train 0.2974 test 0.3646 metric ['0.8682']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 246.74it/s]\n",
      "\u001b[32m2026-02-22 13:24:20.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 5 train 0.2793 test 0.3610 metric ['0.8735']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 234.54it/s]\n",
      "\u001b[32m2026-02-22 13:24:25.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 6 train 0.2666 test 0.3330 metric ['0.8831']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 218.23it/s]\n",
      "\u001b[32m2026-02-22 13:24:29.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 7 train 0.2598 test 0.3589 metric ['0.8725']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:24:29.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3330, current loss 0.3589.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 203.45it/s]\n",
      "\u001b[32m2026-02-22 13:24:34.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 8 train 0.2471 test 0.3433 metric ['0.8781']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:24:34.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3330, current loss 0.3433.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 196.88it/s]\n",
      "\u001b[32m2026-02-22 13:24:40.036\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 9 train 0.2328 test 0.3234 metric ['0.8896']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:43<00:00,  4.39s/it]\n",
      "\u001b[32m2026-02-22 13:24:40.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20260222-132440\u001b[0m\n",
      "\u001b[32m2026-02-22 13:24:40.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 262.43it/s]\n",
      "\u001b[32m2026-02-22 13:24:43.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 0 train 0.5343 test 0.4434 metric ['0.8400']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 221.84it/s]\n",
      "\u001b[32m2026-02-22 13:24:48.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 1 train 0.3776 test 0.3918 metric ['0.8588']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:04<00:00, 218.21it/s]\n",
      "\u001b[32m2026-02-22 13:24:53.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 2 train 0.3406 test 0.3597 metric ['0.8702']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 247.13it/s]\n",
      "\u001b[32m2026-02-22 13:24:57.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 3 train 0.3190 test 0.3581 metric ['0.8706']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 262.17it/s]\n",
      "\u001b[32m2026-02-22 13:25:01.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 4 train 0.2977 test 0.3543 metric ['0.8721']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 256.88it/s]\n",
      "\u001b[32m2026-02-22 13:25:05.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 5 train 0.2843 test 0.3514 metric ['0.8753']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 254.03it/s]\n",
      "\u001b[32m2026-02-22 13:25:09.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 6 train 0.2705 test 0.3417 metric ['0.8773']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 246.09it/s]\n",
      "\u001b[32m2026-02-22 13:25:13.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 7 train 0.2568 test 0.3454 metric ['0.8791']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:25:13.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3417, current loss 0.3454.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 251.00it/s]\n",
      "\u001b[32m2026-02-22 13:25:18.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 8 train 0.2509 test 0.3260 metric ['0.8843']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 254.06it/s]\n",
      "\u001b[32m2026-02-22 13:25:22.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 9 train 0.2424 test 0.3215 metric ['0.8839']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:42<00:00,  4.22s/it]\n",
      "\u001b[32m2026-02-22 13:25:22.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20260222-132522\u001b[0m\n",
      "\u001b[32m2026-02-22 13:25:22.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 283.56it/s]\n",
      "\u001b[32m2026-02-22 13:25:25.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 0 train 0.5518 test 0.4357 metric ['0.8444']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 273.07it/s]\n",
      "\u001b[32m2026-02-22 13:25:29.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 1 train 0.3902 test 0.3884 metric ['0.8585']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 271.57it/s]\n",
      "\u001b[32m2026-02-22 13:25:33.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 2 train 0.3443 test 0.3643 metric ['0.8687']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 269.41it/s]\n",
      "\u001b[32m2026-02-22 13:25:37.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 3 train 0.3274 test 0.3534 metric ['0.8740']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 264.45it/s]\n",
      "\u001b[32m2026-02-22 13:25:41.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 4 train 0.3080 test 0.3495 metric ['0.8752']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 263.64it/s]\n",
      "\u001b[32m2026-02-22 13:25:45.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 5 train 0.2856 test 0.3592 metric ['0.8699']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:25:45.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3495, current loss 0.3592.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 254.89it/s]\n",
      "\u001b[32m2026-02-22 13:25:49.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 6 train 0.2795 test 0.3504 metric ['0.8715']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:25:49.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3495, current loss 0.3504.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 261.41it/s]\n",
      "\u001b[32m2026-02-22 13:25:53.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 7 train 0.2669 test 0.3440 metric ['0.8790']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 263.09it/s]\n",
      "\u001b[32m2026-02-22 13:25:57.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 8 train 0.2574 test 0.3449 metric ['0.8809']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:25:57.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3440, current loss 0.3449.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 253.17it/s]\n",
      "\u001b[32m2026-02-22 13:26:01.453\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 9 train 0.2475 test 0.3389 metric ['0.8808']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:39<00:00,  3.93s/it]\n",
      "\u001b[32m2026-02-22 13:26:01.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20260222-132601\u001b[0m\n",
      "\u001b[32m2026-02-22 13:26:01.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 277.18it/s]\n",
      "\u001b[32m2026-02-22 13:26:05.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 0 train 0.5534 test 0.4521 metric ['0.8433']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 274.56it/s]\n",
      "\u001b[32m2026-02-22 13:26:08.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 1 train 0.3891 test 0.3951 metric ['0.8574']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 266.10it/s]\n",
      "\u001b[32m2026-02-22 13:26:12.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 2 train 0.3507 test 0.3811 metric ['0.8637']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 266.42it/s]\n",
      "\u001b[32m2026-02-22 13:26:16.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 3 train 0.3267 test 0.3501 metric ['0.8707']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 261.95it/s]\n",
      "\u001b[32m2026-02-22 13:26:20.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 4 train 0.3098 test 0.3597 metric ['0.8697']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:26:20.801\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3501, current loss 0.3597.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 265.21it/s]\n",
      "\u001b[32m2026-02-22 13:26:24.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 5 train 0.2893 test 0.3599 metric ['0.8719']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:26:24.714\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3501, current loss 0.3599.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 271.14it/s]\n",
      "\u001b[32m2026-02-22 13:26:28.575\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 6 train 0.2861 test 0.3425 metric ['0.8744']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 268.32it/s]\n",
      "\u001b[32m2026-02-22 13:26:32.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 7 train 0.2709 test 0.3666 metric ['0.8705']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:26:32.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3425, current loss 0.3666.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 263.59it/s]\n",
      "\u001b[32m2026-02-22 13:26:36.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 8 train 0.2620 test 0.3302 metric ['0.8817']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 246.10it/s]\n",
      "\u001b[32m2026-02-22 13:26:40.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 9 train 0.2535 test 0.3446 metric ['0.8793']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:26:40.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3302, current loss 0.3446.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:39<00:00,  3.91s/it]\n",
      "\u001b[32m2026-02-22 13:26:40.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20260222-132640\u001b[0m\n",
      "\u001b[32m2026-02-22 13:26:40.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 278.08it/s]\n",
      "\u001b[32m2026-02-22 13:26:44.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 0 train 0.5692 test 0.4559 metric ['0.8388']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 278.29it/s]\n",
      "\u001b[32m2026-02-22 13:26:48.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 1 train 0.4052 test 0.4220 metric ['0.8497']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 278.07it/s]\n",
      "\u001b[32m2026-02-22 13:26:51.886\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 2 train 0.3580 test 0.4045 metric ['0.8530']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 277.67it/s]\n",
      "\u001b[32m2026-02-22 13:26:55.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 3 train 0.3369 test 0.3693 metric ['0.8672']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 277.41it/s]\n",
      "\u001b[32m2026-02-22 13:26:59.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 4 train 0.3192 test 0.3767 metric ['0.8660']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:26:59.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3693, current loss 0.3767.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 261.07it/s]\n",
      "\u001b[32m2026-02-22 13:27:03.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 5 train 0.2982 test 0.3524 metric ['0.8751']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 268.19it/s]\n",
      "\u001b[32m2026-02-22 13:27:07.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 6 train 0.2896 test 0.3581 metric ['0.8716']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:27:07.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3524, current loss 0.3581.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 246.74it/s]\n",
      "\u001b[32m2026-02-22 13:27:11.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 7 train 0.2824 test 0.3386 metric ['0.8764']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 261.57it/s]\n",
      "\u001b[32m2026-02-22 13:27:15.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 8 train 0.2661 test 0.3463 metric ['0.8715']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:27:15.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3386, current loss 0.3463.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 268.83it/s]\n",
      "\u001b[32m2026-02-22 13:27:19.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 9 train 0.2636 test 0.3418 metric ['0.8742']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:27:19.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3386, current loss 0.3418.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:38<00:00,  3.87s/it]\n",
      "\u001b[32m2026-02-22 13:27:19.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs\\20260222-132719\u001b[0m\n",
      "\u001b[32m2026-02-22 13:27:19.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 267.86it/s]\n",
      "\u001b[32m2026-02-22 13:27:23.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 0 train 0.5954 test 0.4764 metric ['0.8309']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 280.62it/s]\n",
      "\u001b[32m2026-02-22 13:27:26.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 1 train 0.4121 test 0.4186 metric ['0.8499']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 253.51it/s]\n",
      "\u001b[32m2026-02-22 13:27:31.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 2 train 0.3767 test 0.4115 metric ['0.8503']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 259.27it/s]\n",
      "\u001b[32m2026-02-22 13:27:35.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 3 train 0.3496 test 0.4021 metric ['0.8566']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 260.64it/s]\n",
      "\u001b[32m2026-02-22 13:27:39.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 4 train 0.3274 test 0.3773 metric ['0.8625']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 267.09it/s]\n",
      "\u001b[32m2026-02-22 13:27:42.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 5 train 0.3131 test 0.3691 metric ['0.8676']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 272.74it/s]\n",
      "\u001b[32m2026-02-22 13:27:46.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 6 train 0.3009 test 0.3572 metric ['0.8713']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 252.09it/s]\n",
      "\u001b[32m2026-02-22 13:27:50.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 7 train 0.2927 test 0.3461 metric ['0.8767']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 273.14it/s]\n",
      "\u001b[32m2026-02-22 13:27:54.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 8 train 0.2787 test 0.3587 metric ['0.8721']\u001b[0m\n",
      "\u001b[32m2026-02-22 13:27:54.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m258\u001b[0m - \u001b[1mbest loss: 0.3461, current loss 0.3587.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 937/937 [00:03<00:00, 285.85it/s]\n",
      "\u001b[32m2026-02-22 13:27:58.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m215\u001b[0m - \u001b[1mEpoch 9 train 0.2730 test 0.3458 metric ['0.8811']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 10/10 [00:39<00:00,  3.91s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from itertools import product\n",
    "\n",
    "# --- Pas hier je experiment waardes aan ---\n",
    "units = [256, 128, 64]           # units1 en units2\n",
    "epochs_list = [5, 10]            # aantal epochs\n",
    "batchsizes = [32, 64]            # batchsize\n",
    "extra_layers = [True, False]     # extra layer toevoegen?\n",
    "learning_rates = [1e-3, 1e-4]    # learning rate\n",
    "optimizers = ['SGD', 'Adam']     # optimizer keuze\n",
    "# -------------------------------------\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "for unit1, unit2, epochs, batchsize, extra_layer, lr, opt_name in product(\n",
    "    units, units, epochs_list, batchsizes, extra_layers, learning_rates, optimizers\n",
    "):\n",
    "    # Maak model, pas eventueel extra_layer parameter aan\n",
    "    model = NeuralNetwork(num_classes=10, units1=unit1, units2=unit2, extra_layer=extra_layer)\n",
    "\n",
    "    # Maak optimizer\n",
    "    if opt_name == 'SGD':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)\n",
    "\n",
    "    # Settings per run\n",
    "    settings = TrainerSettings(\n",
    "        epochs=epochs,\n",
    "        metrics=[accuracy],\n",
    "        logdir=f\"modellogs/u1_{unit1}_u2_{unit2}_ep_{epochs}_bs_{batchsize}_lr_{lr}_{opt_name}\",\n",
    "        train_steps=len(train),\n",
    "        valid_steps=len(valid),\n",
    "        reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    "    )\n",
    "\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        traindataloader=trainstreamer,\n",
    "        validdataloader=validstreamer,\n",
    "        scheduler=scheduler\n",
    "    )\n",
    "\n",
    "    trainer.loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have set the ReportType to TOML, you will find in every log dir a model.toml and settings.toml file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment, and study the result with tensorboard. \n",
    "\n",
    "Locally, it is easy to do that with VS code itself. On the server, you have to take these steps:\n",
    "\n",
    "- in the terminal, `cd` to the location of the repository\n",
    "- activate the python environment for the shell. Note how the correct environment is being activated.\n",
    "- run `tensorboard --logdir=modellogs` in the terminal\n",
    "- tensorboard will launch at `localhost:6006` and vscode will notify you that the port is forwarded\n",
    "- you can either press the `launch` button in VScode or open your local browser at `localhost:6006`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
